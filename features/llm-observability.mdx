---
title: "Observability"
icon: "magnifying-glass"
---

Just like any other software, LLMs require observability to monitor performance, detect issues, and optimize configurations. Prompt Foundry's observability features provide real-time insights into your LLMs, enabling you to track metrics, logs, and traces. The platform's monitoring capabilities help you identify bottlenecks, troubleshoot problems, and improve the overall performance of your AI applications.

<Note>
  We are actively testing Prompt Foundry observality and logging functionality
  for LLMs in a private beta. If you are interested in helping us refine this
  features please [reach out](mailto:hi@promptfoundry.ai) if you would
  like to participate.
</Note>
