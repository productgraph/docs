---
title: "Welcome"
description: "The ultimate prompt engineering, prompt management, and LLM evaluation tool."
icon: "rocket"
---

**Product Graph** is a prompt engineering tool designed for teams building AI applications.

With its simple and intuitive interface, Product Graph allows you to experiment with models from providers like OpenAI and Anthropic, and effectively refine your prompts and configurations using our robust testing suite.

This test driven approach helps you optimize your prompts, streamline workflows, and boost the effectiveness of your AI applications.

<Card>
  <iframe
    width="670"
    height="377"
    src="https://www.youtube.com/embed/F7PP2SfHNcA"
    title="YouTube video player"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  ></iframe>
</Card>

### LLM Playground

The playground feature in Product Graph lets you experiment with different LLM configurations in real-time. You can compare various OpenAI and Anthropic models, optimize variables, parameters, and message sequences. Additionally, the playground supports advanced features like parallel tool calling and image vision providing a versatile environment for exploring your prompt ideas.

[Learn more about the playground](/features/llm-playground)

### Prompt Management

Product Graph offers a robust management system for your model configuration. With cross-LLM-provider support, you can easily create, edit, and deploy prompts across different platforms. The no-code editing feature simplifies the process, while versioning ensures you can keep track of changes and maintain organized workflows. The platform's intuitive design makes it easy to manage prompts without needing extensive engineering support.

### LLM Evaluations

Ensure the quality and effectiveness of your LLM configuration with Product Graph's comprehensive evaluation tools. You can test your model using predefined cases and assertions, leveraging deterministic rule-based methods, LLM-based assessments, and human reviews. This multi-faceted evaluation approach enhances your confidence in prompt deployment, ensuring they perform as expected in real-world scenarios.

[Learn more about evaluations](/features/llm-evaluations)

### LLM Observability

Just like any other software, LLMs require observability to monitor performance, detect issues, and optimize configurations. Product Graph's observability features provide real-time insights into your LLMs, enabling you to track metrics, logs, and traces. The platform's monitoring capabilities help you identify bottlenecks, troubleshoot problems, and improve the overall performance of your AI applications.

[Learn more about observability](/features/llm-observability)

### SDK

Product Graph provides full control over your LLM integration with its powerful SDKs and API. Whether you're using OpenAI or Anthropic, the platform's SDKs offer extensive features to manage your prompts and integrate them seamlessly into your applications.

<CardGroup cols={1}>
  <Card title="Node Quickstart" href="/libraries/node" icon="js">
    Get started with the Node.js library.
  </Card>
  <Card title="Python Quickstart" href="/libraries/python" icon="python">
    Get started with the Python library.
  </Card>
  <Card title="OpenAPI Quickstart" href="/libraries/open-api" icon="terminal">
    Generate a client in your preferred programming language.
  </Card>
</CardGroup>
